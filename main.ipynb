{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8796ade-58a1-433c-8d62-fc1b5a72da5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Month_Year     PS    T2M   RH2M    WD2M  WS2M  PRECTOTCORR\n",
      "0   2003 Jan  99.42  26.12  64.50  348.12  1.48          0.0\n",
      "1   2003 Feb  99.25  28.18  61.75  303.25  1.86          0.0\n",
      "2   2003 Mar  99.16  29.47  60.81  292.50  1.95          0.0\n",
      "3   2003 Apr  99.02  29.82  66.88  286.19  1.84          0.0\n",
      "4   2003 May  98.98  29.49  70.25  296.38  2.47          0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the new CSV file into a DataFrame\n",
    "file_path = \"newWeather.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to verify the data\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de0d39f-20bd-4847-9dc2-a46aa900dead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Month_Year     PS    T2M   RH2M    WD2M  WS2M  PRECTOTCORR\n",
      "0   2003 Jan  99.42  26.12  64.50  348.12  1.48          0.0\n",
      "1   2003 Feb  99.25  28.18  61.75  303.25  1.86          0.0\n",
      "2   2003 Mar  99.16  29.47  60.81  292.50  1.95          0.0\n",
      "3   2003 Apr  99.02  29.82  66.88  286.19  1.84          0.0\n",
      "4   2003 May  98.98  29.49  70.25  296.38  2.47          0.0\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Optionally, you can remove outliers or handle them as needed\n",
    "# For demonstration, let's remove rows where any column has a value that is an extreme outlier\n",
    "\n",
    "# Define a function to detect outliers using Z-score\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "def remove_outliers(df, z_thresh=3):\n",
    "    return df[(np.abs(stats.zscore(df.select_dtypes(include=[np.number]))) < z_thresh).all(axis=1)]\n",
    "\n",
    "# Remove outliers\n",
    "df = remove_outliers(df)\n",
    "\n",
    "# Display the DataFrame after cleaning\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac106e00-3b76-4195-b1c4-c174f6cc2e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Month_Year     PS    T2M   RH2M    WD2M  WS2M  PRECTOTCORR\n",
      "0   2003 Jan  99.42  26.12  64.50  348.12  1.48          0.0\n",
      "1   2003 Feb  99.25  28.18  61.75  303.25  1.86          0.0\n",
      "2   2003 Mar  99.16  29.47  60.81  292.50  1.95          0.0\n",
      "3   2003 Apr  99.02  29.82  66.88  286.19  1.84          0.0\n",
      "4   2003 May  98.98  29.49  70.25  296.38  2.47          0.0\n",
      "Original shape: (237, 7)\n",
      "Shape after removing outliers: (235, 7)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "def remove_outliers(df, z_thresh=3):\n",
    "    return df[(np.abs(stats.zscore(df.select_dtypes(include=[np.number]))) < z_thresh).all(axis=1)]\n",
    "\n",
    "# Remove outliers\n",
    "df_clean = remove_outliers(df)\n",
    "\n",
    "# Display the DataFrame after cleaning\n",
    "print(df_clean.head())\n",
    "print(\"Original shape:\", df.shape)\n",
    "print(\"Shape after removing outliers:\", df_clean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37e17c3e-d0da-4a19-932f-d15de5a00fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month_Year</th>\n",
       "      <th>PS</th>\n",
       "      <th>T2M</th>\n",
       "      <th>RH2M</th>\n",
       "      <th>WD2M</th>\n",
       "      <th>WS2M</th>\n",
       "      <th>PRECTOTCORR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003 Jan</td>\n",
       "      <td>99.42</td>\n",
       "      <td>26.12</td>\n",
       "      <td>64.50</td>\n",
       "      <td>348.12</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003 Feb</td>\n",
       "      <td>99.25</td>\n",
       "      <td>28.18</td>\n",
       "      <td>61.75</td>\n",
       "      <td>303.25</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003 Mar</td>\n",
       "      <td>99.16</td>\n",
       "      <td>29.47</td>\n",
       "      <td>60.81</td>\n",
       "      <td>292.50</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003 Apr</td>\n",
       "      <td>99.02</td>\n",
       "      <td>29.82</td>\n",
       "      <td>66.88</td>\n",
       "      <td>286.19</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003 May</td>\n",
       "      <td>98.98</td>\n",
       "      <td>29.49</td>\n",
       "      <td>70.25</td>\n",
       "      <td>296.38</td>\n",
       "      <td>2.47</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2022 Aug</td>\n",
       "      <td>98.88</td>\n",
       "      <td>25.35</td>\n",
       "      <td>90.62</td>\n",
       "      <td>284.12</td>\n",
       "      <td>2.64</td>\n",
       "      <td>32.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2022 Sep</td>\n",
       "      <td>99.02</td>\n",
       "      <td>25.39</td>\n",
       "      <td>88.38</td>\n",
       "      <td>274.94</td>\n",
       "      <td>2.06</td>\n",
       "      <td>12.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2022 Oct</td>\n",
       "      <td>99.12</td>\n",
       "      <td>25.72</td>\n",
       "      <td>83.50</td>\n",
       "      <td>278.69</td>\n",
       "      <td>1.45</td>\n",
       "      <td>4.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2022 Nov</td>\n",
       "      <td>99.20</td>\n",
       "      <td>26.10</td>\n",
       "      <td>76.31</td>\n",
       "      <td>195.88</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2022 Dec</td>\n",
       "      <td>99.17</td>\n",
       "      <td>26.09</td>\n",
       "      <td>73.19</td>\n",
       "      <td>38.50</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month_Year     PS    T2M   RH2M    WD2M  WS2M  PRECTOTCORR\n",
       "0     2003 Jan  99.42  26.12  64.50  348.12  1.48         0.00\n",
       "1     2003 Feb  99.25  28.18  61.75  303.25  1.86         0.00\n",
       "2     2003 Mar  99.16  29.47  60.81  292.50  1.95         0.00\n",
       "3     2003 Apr  99.02  29.82  66.88  286.19  1.84         0.00\n",
       "4     2003 May  98.98  29.49  70.25  296.38  2.47         0.00\n",
       "..         ...    ...    ...    ...     ...   ...          ...\n",
       "235   2022 Aug  98.88  25.35  90.62  284.12  2.64        32.15\n",
       "236   2022 Sep  99.02  25.39  88.38  274.94  2.06        12.72\n",
       "237   2022 Oct  99.12  25.72  83.50  278.69  1.45         4.31\n",
       "238   2022 Nov  99.20  26.10  76.31  195.88  1.05         1.73\n",
       "239   2022 Dec  99.17  26.09  73.19   38.50  1.24         1.42\n",
       "\n",
       "[237 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4153bdf-ca3f-4fce-a668-aa3bd52385e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_classification_threshold\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     FixedThresholdClassifier,\n\u001b[0;32m      5\u001b[0m     TunedThresholdClassifierCV,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_plot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LearningCurveDisplay, ValidationCurveDisplay\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_search\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV, ParameterGrid, ParameterSampler, RandomizedSearchCV\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_classification_threshold.py:14\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     BaseEstimator,\n\u001b[0;32m      8\u001b[0m     ClassifierMixin,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     clone,\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NotFittedError\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     15\u001b[0m     check_scoring,\n\u001b[0;32m     16\u001b[0m     get_scorer_names,\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_scorer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _BaseScorer\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _safe_indexing\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`sklearn.metrics` module includes score functions, performance metrics\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mand pairwise metrics and distance computations.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cluster\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_classification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     accuracy_score,\n\u001b[0;32m      9\u001b[0m     balanced_accuracy_score,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m     zero_one_loss,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dist_metrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistanceMetric\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\cluster\\__init__.py:26\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bicluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m consensus_score\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_supervised\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     adjusted_mutual_info_score,\n\u001b[0;32m     12\u001b[0m     adjusted_rand_score,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     v_measure_score,\n\u001b[0;32m     25\u001b[0m )\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_unsupervised\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     calinski_harabasz_score,\n\u001b[0;32m     28\u001b[0m     davies_bouldin_score,\n\u001b[0;32m     29\u001b[0m     silhouette_samples,\n\u001b[0;32m     30\u001b[0m     silhouette_score,\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     33\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madjusted_mutual_info_score\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalized_mutual_info_score\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsensus_score\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     53\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:23\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _atol_for_type\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     Interval,\n\u001b[0;32m     20\u001b[0m     StrOptions,\n\u001b[0;32m     21\u001b[0m     validate_params,\n\u001b[0;32m     22\u001b[0m )\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _VALID_METRICS, pairwise_distances, pairwise_distances_chunked\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_number_of_labels\u001b[39m(n_labels, n_samples):\n\u001b[0;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that number of labels are valid.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m        Number of samples.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _num_samples, check_non_negative\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pairwise_distances_reduction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArgKmin\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pairwise_fast\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _chi2_kernel_fast, _sparse_manhattan\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Utility Functions\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_return_float_dtype\u001b[39m(X, Y):\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:645\u001b[0m, in \u001b[0;36mparent\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15f9bd4-6193-4198-8b1b-0432a20b6095",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80cf100-af3d-48c2-82be-9d9458208eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot histograms for each numeric column\n",
    "df_clean.hist(bins=30, figsize=(15, 10))\n",
    "plt.suptitle(\"Histograms of Cleaned Data\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add31c63-7789-41b2-b8f0-0811e60b2852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot box plots for each numeric column\n",
    "df_clean.plot(kind='box', subplots=True, layout=(3, 3), figsize=(15, 10), sharex=False, sharey=False)\n",
    "plt.suptitle(\"Box Plots of Cleaned Data\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f5a7e0-622f-4843-ba10-1a730e566bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Exclude non-numeric columns\n",
    "numeric_df = df_clean.select_dtypes(include=[np.number])\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = numeric_df.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960687b3-af23-472d-ad0d-3a8f2c9bb097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scatter plots for pairs of features\n",
    "sns.pairplot(df_clean)\n",
    "plt.suptitle(\"Scatter Plots of Feature Pairs\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6d33a8-fd00-469d-9fd7-28872ad2d0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a048fa0c-68db-477e-aa0a-8aa82d320321",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1154a9dd-0218-471a-ad0b-66424faad391",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[data.columns[1:6]]\n",
    "y=data['PRECTOTCORR']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "model=LinearRegression()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b21296-7423-40af-b762-330cb4273227",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(X_test)\n",
    "plt.scatter(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1835898a-5376-4b30-b2e6-ba1c5883e349",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af348027-d196-4b65-a2fc-91ff75fe89b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370f65d2-a936-4d6e-b8db-d7105e5b808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_reg=PolynomialFeatures(degree=2)\n",
    "X_train_poly=poly_reg.fit_transform(X_train)\n",
    "X_test_poly=poly_reg.fit_transform(X_test)\n",
    "model2=LinearRegression()\n",
    "model2.fit(X_train_poly,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0513162a-911a-402d-847d-1df9d1f05903",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2=model2.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27df0516-8787-453a-8b36-305f8eab199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6383dd-d0a9-4c02-a967-a0bfeab3e78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with Random Forest\n",
    "rf_test_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Plot Random Forest predictions\n",
    "plt.scatter(y_test, rf_test_predictions)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.title(\"Random Forest Regressor Predictions\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b40087c-88dc-4aba-9ece-e78ed7878d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Define a function to evaluate and print metrics\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    train_predictions = model.predict(X_train)\n",
    "    test_predictions = model.predict(X_test)\n",
    "    \n",
    "    print(\"Model Performance on Training Data:\")\n",
    "    print(\"MAE:\", mean_absolute_error(y_train, train_predictions))\n",
    "    print(\"MSE:\", mean_squared_error(y_train, train_predictions))\n",
    "    print(\"R-squared:\", r2_score(y_train, train_predictions))\n",
    "    \n",
    "    print(\"\\nModel Performance on Test Data:\")\n",
    "    print(\"MAE:\", mean_absolute_error(y_test, test_predictions))\n",
    "    print(\"MSE:\", mean_squared_error(y_test, test_predictions))\n",
    "    print(\"R-squared:\", r2_score(y_test, test_predictions))\n",
    "\n",
    "# Evaluate Linear Regression model\n",
    "print(\"Linear Regression Model:\")\n",
    "evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Evaluate Polynomial Regression model\n",
    "print(\"\\nPolynomial Regression Model:\")\n",
    "evaluate_model(model2, X_train_poly, X_test_poly, y_train, y_test)\n",
    "\n",
    "# Evaluate Random Forest model\n",
    "print(\"\\nRandom Forest Model:\")\n",
    "evaluate_model(rf_model, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d587a39a-7686-41f9-a070-aa0407295b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with Random Forest\n",
    "rf_train_predictions = rf_model.predict(X_train)\n",
    "rf_test_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate Random Forest model\n",
    "print(\"Random Forest Regressor Performance on Training Data:\")\n",
    "print(\"MAE:\", mean_absolute_error(y_train, rf_train_predictions))\n",
    "print(\"MSE:\", mean_squared_error(y_train, rf_train_predictions))\n",
    "print(\"R-squared:\", r2_score(y_train, rf_train_predictions))\n",
    "\n",
    "print(\"\\nRandom Forest Regressor Performance on Test Data:\")\n",
    "print(\"MAE:\", mean_absolute_error(y_test, rf_test_predictions))\n",
    "print(\"MSE:\", mean_squared_error(y_test, rf_test_predictions))\n",
    "print(\"R-squared:\", r2_score(y_test, rf_test_predictions))\n",
    "\n",
    "# Plot Random Forest predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot for test data\n",
    "plt.scatter(y_test, rf_test_predictions, color='blue', alpha=0.6, label='Predictions')\n",
    "\n",
    "# Diagonal line indicating perfect predictions\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', linewidth=2, label='Perfect Predictions')\n",
    "\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.title(\"Random Forest Regressor Predictions\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d48d85-72af-4344-aef3-4911404e6097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "test_residuals = y_test - rf_test_predictions\n",
    "\n",
    "# Residual plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(rf_test_predictions, test_residuals, color='blue', alpha=0.6)\n",
    "plt.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05644096-7286-4a75-9172-69217f083be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "feature_importances = rf_model.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(X.shape[1]), feature_importances[indices], align='center')\n",
    "plt.xticks(range(X.shape[1]), features[indices], rotation=90)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importance Plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ecc88c-3c58-4988-aa22-946bf856fdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Learning curve function\n",
    "def plot_learning_curve(model, X, y):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    train_scores_mean = -train_scores.mean(axis=1)\n",
    "    test_scores_mean = -test_scores.mean(axis=1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color='r', label='Training Score')\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color='g', label='Cross-validation Score')\n",
    "    plt.xlabel('Training examples')\n",
    "    plt.ylabel('Mean Squared Error')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot learning curve\n",
    "plot_learning_curve(rf_model, X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc44079-1582-4c54-9abb-b1cabb9148ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on training data\n",
    "rf_train_predictions = rf_model.predict(X_train)\n",
    "\n",
    "# Plot predictions on training data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_train, rf_train_predictions, color='green', alpha=0.6)\n",
    "plt.plot([min(y_train), max(y_train)], [min(y_train), max(y_train)], color='red', linestyle='--', linewidth=2)\n",
    "plt.xlabel('True Values (Training Data)')\n",
    "plt.ylabel('Predictions (Training Data)')\n",
    "plt.title('Random Forest Regressor Predictions on Training Data')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f134452e-ec8f-49a6-bfb3-b458b7025be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions on test data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, rf_test_predictions, color='blue', alpha=0.6)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', linewidth=2)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.title('Random Forest Regressor Predictions on Test Data')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70090d30-34ae-4cf1-b6cd-7c02cafb161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "def load_model_and_predict(new_data):\n",
    "    # Load the model\n",
    "    rf_model = joblib.load('random_forest_regressor_model.pkl')\n",
    "\n",
    "    # Create a DataFrame from new data\n",
    "    new_data_df = pd.DataFrame(new_data)\n",
    "\n",
    "    \n",
    "    # Ensure the columns are in the same order as during training\n",
    "    new_data_df = new_data_df[['PS', 'T2M', 'RH2M', 'WD2M', 'WS2M']]\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = rf_model.predict(new_data_df)\n",
    "\n",
    "\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Example usage with new data\n",
    "new_test_data = {\n",
    "    'PS': [99.28, 98.97, 98.94, 99.29, ],\n",
    "    'T2M': [27.68, 25.78, 28.22, 26.53,],\n",
    "    'RH2M': [57.12, 91.31, 77.19, 64.0,],\n",
    "    'WD2M': [293.5, 271.56, 274.38, 311.37, ],\n",
    "    'WS2M': [1.79, 3.02, 2.49, 1.66, ]\n",
    "}\n",
    "\n",
    "predictions = load_model_and_predict(new_test_data)\n",
    "print(\"Predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c25abc-6816-494c-96c4-410923c5d267",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import joblib\n",
    "    import pandas as pd\n",
    "except ImportError as e:\n",
    "    print(f\"Failed to import required libraries: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "def load_model_and_predict(new_data):\n",
    "    try:\n",
    "        # Load the model\n",
    "        rf_model = joblib.load('random_forest_regressor_model.pkl')\n",
    "\n",
    "        # Create a DataFrame from new data\n",
    "        new_data_df = pd.DataFrame(new_data)\n",
    "\n",
    "        # Ensure the columns are in the same order as during training\n",
    "        new_data_df = new_data_df[['PS', 'T2M', 'RH2M', 'WD2M', 'WS2M']]\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = rf_model.predict(new_data_df)\n",
    "\n",
    "        # Define precipitation ranges and corresponding weather descriptions\n",
    "        weather_descriptions = {\n",
    "            \"Sunny\": (0, 0.0, \"0 mm/day (No precipitation)\"),\n",
    "            \"Partly Cloudy/Overcast\": (0.1, 0.5, \"0 to 0.5 mm/day (Very light drizzle or no precipitation)\"),\n",
    "            \"Light Rain\": (0.6, 5.0, \"0.6 to 5 mm/day (Light rain)\"),\n",
    "            \"Moderate Rain\": (5.1, 15.0, \"5.1 to 15 mm/day (Moderate rain)\"),\n",
    "            \"Heavy Rain\": (15.1, 30.0, \"15.1 to 30 mm/day (Heavy rain)\"),\n",
    "            \"Very Heavy Rain/Thunderstorm\": (30.1, 40.0, \"30.1 to 40 mm/day (Very heavy rain or thunderstorm conditions)\")\n",
    "        }\n",
    "\n",
    "        # Determine weather description based on predicted precipitation\n",
    "        weather_predictions = []\n",
    "        for prediction in predictions:\n",
    "            predicted_weather = \"Unknown\"\n",
    "            for weather, (range_start, range_end, description) in weather_descriptions.items():\n",
    "                if range_start <= prediction <= range_end:\n",
    "                    predicted_weather = weather\n",
    "                    weather_predictions.append((prediction, predicted_weather, description))\n",
    "                    break\n",
    "\n",
    "        return weather_predictions\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage with new data\n",
    "new_test_data = {\n",
    "    'PS': [99.28, 98.97, 98.94, 99.29],\n",
    "    'T2M': [27.68, 25.78, 28.22, 26.53],\n",
    "    'RH2M': [57.12, 91.31, 77.19, 64.0],\n",
    "    'WD2M': [293.5, 271.56, 274.38, 311.37],\n",
    "    'WS2M': [1.79, 3.02, 2.49, 1.66]\n",
    "}\n",
    "\n",
    "predictions = load_model_and_predict(new_test_data)\n",
    "if predictions is not None:\n",
    "    for prediction in predictions:\n",
    "        print(f\"Prediction: {prediction[0]} mm/day\")\n",
    "        print(f\"Weather: {prediction[1]}\")\n",
    "        print(f\"Description: {prediction[2]}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed6553-33d7-4e82-81d4-aec97cde5dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
